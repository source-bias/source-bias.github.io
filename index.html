<!DOCTYPE HTML>
<html>

<head>
    <meta charset="utf-8">
    <title>Source Bias</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="style/css/bootstrap.css">
    <link rel="stylesheet" href="style/css/style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css"> 
    <style>
        .tldr { font-weight: bold; color: #444; }
        .publication-links a { margin-right: 10px; }
    </style>
</head>

<nav class="fh5co-nav" role="navigation">
    <div class="top-menu">
        <div class="container">
            <ul class="menu-1">
                <li><a href="#home">Home</a></li>
                <li><a href="#Information-Retrieval">Information Retrieval</a></li>
                <li><a href="#Image-Retrieval">Image Retrieval</a></li>
                <li><a href="#Recommender-System">Recommender System</a></li>
                <li><a href="#Video-Retrieval">Video Retrieval</a></li>
                <li><a href="#Theorem-Analysis">Theorem Analysis</a></li>
                <li><a href="#Mitigating-Bias">Mitigating Bias</a></li>
                <li><a href="#Benchmark-Cocktail">Benchmark Cocktail</a></li>
                <li><a href="#Survey">Survey</a></li>
                <li><a href="#contact">Contact</a></li>
            </ul>
        </div>
    </div>
</nav>


<section id="Recommender-System" class="fh5co-section" style="margin-top: 50px; padding-top: 50px;">
    <div class="container">
        <div class="row">
            <div class="col-md-12">
                <h1>Source Bias in Recommender System</h1>
                    <div class="content has-text-justified">
                        <a href="# Recommender-System"> (SIGIR 2025) Exploring the Escalation of Source Bias in User, Data, and Recommender System Feedback Loop </a>
                        <br>
                            - This paper investigates <b>source bias</b> in recommender systems caused by the rise of AI-generated content (AIGC) from large language models (LLMs). The authors show that AIGC tends to be ranked higher than human-written content, a bias that worsens over time due to a <b>feedback loop</b> involving user interactions and model retraining. Through extensive experiments, they identify three stages of AIGC integration—HGC-dominant, coexistence, and AIGC-dominant phases—and demonstrate how source bias escalates through them. To mitigate this, they propose a <b>black-box debiasing method</b> using L1 loss to align embeddings of human and AI-generated content, which maintains fairness and performance over time.
            
            </div>
        </div>
    </div>
</section>

<br>
<section class="section" id="bibtex">
	<div class="container is-max-desktop content">
		<h2 class="title">BibTeX</h2>
<pre><code>@article{zhou2025source,
	title={Exploring the Escalation of Source Bias in User, Data, and Recommender System Feedback Loop},
	author={Zhou, Yuqi and Dai, Sunhao and Pang, Liang and Wang, Gang and Dong, Zhenhua and Xu, Jun and Wen, Ji-Rong},
	journal={Proceedings of the 48th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	year={2025}
}</code></pre>
	</div>
</section>
    
</html>
