<!DOCTYPE HTML>
<html>

<head>
    <meta charset="utf-8">
    <title>Source Bias</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="style/css/bootstrap.css">
    <link rel="stylesheet" href="style/css/style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <link rel="icon" type="image/x-icon" href="static/images/logo.ico?v=1">

    <style>
        .tldr { font-weight: bold; color: #444; }
        .publication-links a { margin-right: 10px; }
    </style>
</head>

<nav class="fh5co-nav" role="navigation">
    <div class="top-menu">
        <div class="container">
            <ul class="menu-1">
                <li><a href="#home">Home</a></li>
                <li><a href="#Text-Retrieval">Text Retrieval</a></li>
                <li><a href="#Image-Retrieval">Image Retrieval</a></li>
                <li><a href="#Recommender-System">Recommender System</a></li>
                <li><a href="#Video-Retrieval">Video Retrieval</a></li>
                <li><a href="#Theorem-Analysis">Theorem Analysis</a></li>
                <li><a href="#Mitigating-Bias">Mitigating Bias</a></li>
                <li><a href="#Benchmark-Cocktail">Benchmark Cocktail</a></li>
                <li><a href="#Survey">Survey</a></li>
                <li><a href="#contact">Contact</a></li>
            </ul>
        </div>
    </div>
</nav>

<header id="fh5co-header" class="fh5co-cover" role="banner">
	<div class="overlay"></div>
	<div class="container">
		<div class="columns">
			<div class="col-md-12">
				<div class="text-center">
					<img src="static/images/source_bias_logo.png" alt="Source Bias" style="max-width: 280px; width: 60%;">
				</div>
					
				<h1 id="home" style="font-size: 30px; text-align: center;">
					Source Bias: A New Challenge When Generative AI Meets Information Retrieval
				</h1>
			</div>
		</div>
	</div>
</header>

<section id="Text-Retrieval" class="fh5co-section" style="margin-top: 50px; padding-top: 50px;">
    <div class="container">
        <div class="row">
            <div class="col-md-12">
                <h1>Source Bias in Text Retrieval </h1>
                    <div class="content has-text-justified">
                        <a href="#Text-Retrieval"> (KDD 2024) Neural Retrievers are Biased Towards LLM-Generated Content </a>
                        <br>
			<div class="column has-text-centered">
			    <div class="publication-links">
			        <span class="link-block">
			            <a href="https://dl.acm.org/doi/abs/10.1145/3637528.3671882" target="_blank" class="external-link button is-outlined is-primary">
			                <span class="button-62">Paper</span>
			            </a>
			        </span>
			
			        <span class="link-block">
			            <a href="https://github.com/KID-22/Source-Bias"  target="_blank" class="external-link button is-outlined is-primary">
			                <span class="button-62">Code</span>
			            </a>
			        </span>
			    </div>
			</div>
                        <br>
                            <b>TL;DR</b>: This paper investigates a new challenge for information retrieval (IR) in the era of large language models (LLMs): source bias—the tendency of neural retrievers to favor LLM-generated content over human-written text. This paper build two novel benchmarks (SciFact+AIGC and NQ320K+AIGC) by pairing semantically equivalent human and LLM-generated documents. Experiments reveal that source bias is prevalent not only in neural retrievers but also in re-rankers, rooted in the compressed, noise-reduced nature of LLM texts that align better with pretrained language model representations. To mitigate this, this paper propose a simple, model-agnostic debiasing constraint added to the training objective, which effectively reduces source bias without sacrificing retrieval performance. This work raises critical concerns for the sustainability and fairness of content access in LLM-dominated ecosystems.
            </div>
        </div>
    </div>
</section>

<be>
<section class="section" id="bibtex">
	<div class="container is-max-desktop content">
		<h2 class="title">BibTeX</h2>
<pre><code>@article{dai2024neural,
	  title={Neural Retrievers are Biased Towards LLM-Generated Content},
	  author={Dai, Sunhao and Zhou, Yuqi and Pang, Liang and Liu, Weihao and Hu, Xiaolin and Liu, Yong and Zhang, Xiao and Wang, Gang and Xu, Jun},
	  journal={Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
	  year={2024}
}</code></pre>
	</div>
</section>

	
<section id="Recommender-System" class="fh5co-section" style="margin-top: 50px; padding-top: 50px;">
    <div class="container">
        <div class="row">
            <div class="col-md-12">
                <h1>Source Bias in Recommender System</h1>
                    <div class="content has-text-justified">
                        <a href="# Recommender-System"> (SIGIR 2025) Exploring the Escalation of Source Bias in User, Data, and Recommender System Feedback Loop </a>
			<br>
			<div class="column has-text-centered">
			    <div class="publication-links">
			        <span class="link-block">
			            <a href="https://arxiv.org/pdf/2405.17998" target="_blank" class="external-link button is-outlined is-primary">
			                <span class="button-62">Paper</span>
			            </a>
			        </span>
			
			        <span class="link-block">
			            <a href="https://github.com/Yuqi-Zhou/Rec_SourceBias"  target="_blank" class="external-link button is-outlined is-primary">
			                <span class="button-62">Code</span>
			            </a>
			        </span>
			    </div>
			</div>
                        <br>
                            <b>TL;DR</b>: This paper investigates <b>source bias</b> in recommender systems caused by the rise of AI-generated content (AIGC) from large language models (LLMs). The authors show that AIGC tends to be ranked higher than human-written content, a bias that worsens over time due to a <b>feedback loop</b> involving user interactions and model retraining. Through extensive experiments, they identify three stages of AIGC integration—HGC-dominant, coexistence, and AIGC-dominant phases—and demonstrate how source bias escalates through them. To mitigate this, they propose a <b>black-box debiasing method</b> using L1 loss to align embeddings of human and AI-generated content, which maintains fairness and performance over time.
            
            </div>
        </div>
    </div>
</section>

<br>
<section class="section" id="bibtex">
	<div class="container is-max-desktop content">
		<h2 class="title">BibTeX</h2>
<pre><code>@article{zhou2025source,
	title={Exploring the Escalation of Source Bias in User, Data, and Recommender System Feedback Loop},
	author={Zhou, Yuqi and Dai, Sunhao and Pang, Liang and Wang, Gang and Dong, Zhenhua and Xu, Jun and Wen, Ji-Rong},
	journal={Proceedings of the 48th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	year={2025}
}</code></pre>
	</div>
</section>
    
</html>


<section id="Benchmark-Cocktail" class="fh5co-section" style="margin-top: 50px; padding-top: 50px;">
    <div class="container">
        <div class="row">
            <div class="col-md-12">
                <h1>Cocktail benchmark</h1>
                    <div class="content has-text-justified">
                        <a href="# Benchmark-Cocktail"> (ACL 2024 Findings) Cocktail: A Comprehensive Information Retrieval Benchmark with LLM-Generated Documents Integration </a>
			<br>
			<div class="column has-text-centered">
			    <div class="publication-links">
			        <span class="link-block">
			            <a href="https://aclanthology.org/2024.findings-acl.421.pdf" target="_blank" class="external-link button is-outlined is-primary">
			                <span class="button-62">Paper</span>
			            </a>
			        </span>
			
			        <span class="link-block">
			            <a href="https://github.com/KID-22/Cocktail"  target="_blank" class="external-link button is-outlined is-primary">
			                <span class="button-62">Code</span>
			            </a>
			        </span>
			    </div>
			</div>
                        <br>
                            <b>TL;DR</b>: We introduce <b>Cocktail</b>, the first large-scale IR benchmark tailored for the LLM era, integrating both human‑written and LLM‑generated content. It covers 16 diverse datasets: 15 classic IR corpora (like MS MARCO, TREC, and BEIR) rewritten with Llama2, plus a new dataset, <b>NQ‑UTD</b>, with recent-event queries to mitigate potential bias from previously included dataset information in LLMs. Based on over 1,000 experiments with state-of-the-art neural retrievers, we discovered a striking source bias: models tend to favor AI-generated passages even when they are semantically identical to human-written ones. Moreover, we observe a clear <b>performance–bias trade‑off</b>—higher-ranking accuracy correlates with stronger bias. Moving forward, we highlight the imperative for future IR systems to finely balance accuracy and fairness in mixed-content environments.
            
            </div>
        </div>
    </div>
</section>

<br>
<section class="section" id="bibtex">
	<div class="container is-max-desktop content">
		<h2 class="title">BibTeX</h2>
<pre><code>@article{dai2024cocktail,
	title={Cocktail: A Comprehensive Information Retrieval Benchmark with LLM-Generated Documents Integration},
  	author={Dai, Sunhao and Liu, Weihao and Zhou, Yuqi and Pang, Liang and Ruan, Rongju and Wang, Gang and Dong, Zhenhua and Xu, Jun and Wen, Ji-Rong},
  	journal={Findings of the Association for Computational Linguistics: ACL 2024},
  	year={2024}
}</code></pre>
	</div>
</section>
    
</html>
